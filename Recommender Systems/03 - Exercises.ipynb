{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bc7da27",
   "metadata": {},
   "source": [
    "## Aula 03 - Filtragem Baseada em Conteúdo - Exercícios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "79b9eeb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "584555e1",
   "metadata": {},
   "source": [
    "### Importar base de dados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2e09904e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under ml-20m-compact.tar (16).gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x dataset/\n",
      "x dataset/tags_sample.csv\n",
      "x dataset/._.DS_Store\n",
      "x dataset/.DS_Store\n",
      "x dataset/movies_sample.csv\n",
      "x dataset/._genome-tags.csv\n",
      "x dataset/genome-tags.csv\n",
      "x dataset/._ml-youtube.csv\n",
      "x dataset/ml-youtube.csv\n",
      "x dataset/._genome-scores.csv\n",
      "x dataset/genome-scores.csv\n",
      "x dataset/ratings_sample.csv\n"
     ]
    }
   ],
   "source": [
    "import wget\n",
    "!python -m wget https://github.com/mmanzato/MBABigData/raw/master/ml-20m-compact.tar.gz\n",
    "!tar -xvzf ml-20m-compact.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3e6de1a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>11</td>\n",
       "      <td>7481</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Enemy Mine (1985)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>11</td>\n",
       "      <td>1046</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Beautiful Thing (1996)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>616</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11</td>\n",
       "      <td>3535</td>\n",
       "      <td>2.0</td>\n",
       "      <td>American Psycho (2000)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>11</td>\n",
       "      <td>5669</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Bowling for Columbine (2002)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190616</th>\n",
       "      <td>138493</td>\n",
       "      <td>288</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Natural Born Killers (1994)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190617</th>\n",
       "      <td>138493</td>\n",
       "      <td>1748</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dark City (1998)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190618</th>\n",
       "      <td>138493</td>\n",
       "      <td>616</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Aristocats, The (1970)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190619</th>\n",
       "      <td>138493</td>\n",
       "      <td>1597</td>\n",
       "      <td>4.5</td>\n",
       "      <td>Conspiracy Theory (1997)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190620</th>\n",
       "      <td>138493</td>\n",
       "      <td>7371</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Dogville (2003)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>190621 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        userId  movieId  rating                         title\n",
       "0           11     7481     5.0             Enemy Mine (1985)\n",
       "1           11     1046     4.5        Beautiful Thing (1996)\n",
       "2           11      616     4.0        Aristocats, The (1970)\n",
       "3           11     3535     2.0        American Psycho (2000)\n",
       "4           11     5669     5.0  Bowling for Columbine (2002)\n",
       "...        ...      ...     ...                           ...\n",
       "190616  138493      288     5.0   Natural Born Killers (1994)\n",
       "190617  138493     1748     5.0              Dark City (1998)\n",
       "190618  138493      616     4.0        Aristocats, The (1970)\n",
       "190619  138493     1597     4.5      Conspiracy Theory (1997)\n",
       "190620  138493     7371     5.0               Dogville (2003)\n",
       "\n",
       "[190621 rows x 4 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies = pd.read_csv('./dataset/movies_sample.csv')\n",
    "ratings = pd.read_csv('./dataset/ratings_sample.csv')\n",
    "df = ratings[['userId', 'movieId', 'rating']]\n",
    "df = df.merge(movies[['movieId', 'title']])\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9e082ff9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>Gregory Peck</td>\n",
       "      <td>1329962459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>need to own</td>\n",
       "      <td>1329962471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>romantic comedy</td>\n",
       "      <td>1329962476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>Rome</td>\n",
       "      <td>1329962490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>279</td>\n",
       "      <td>916</td>\n",
       "      <td>royalty</td>\n",
       "      <td>1329962474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag  timestamp_y\n",
       "0     279      916     Gregory Peck   1329962459\n",
       "1     279      916      need to own   1329962471\n",
       "2     279      916  romantic comedy   1329962476\n",
       "3     279      916             Rome   1329962490\n",
       "4     279      916          royalty   1329962474"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_tags = pd.read_csv('./dataset/tags_sample.csv')\n",
    "movies_tags.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6ca49cb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "map_users = {user: idx for idx, user in enumerate(df.userId.unique())}\n",
    "map_items = {item: idx for idx, item in enumerate(df.movieId.unique())}\n",
    "df['userId'] = df['userId'].map(map_users)\n",
    "df['movieId'] = df['movieId'].map(map_items)\n",
    "movies_tags['userId'] = movies_tags['userId'].map(map_users)\n",
    "movies_tags['movieId'] = movies_tags['movieId'].map(map_items)\n",
    "map_title = {}\n",
    "\n",
    "for _, row in df.iterrows():\n",
    "    map_title[row.movieId] = row.title\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f5ed688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>tag</th>\n",
       "      <th>timestamp_y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>Gregory Peck</td>\n",
       "      <td>1329962459</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>need to own</td>\n",
       "      <td>1329962471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>romantic comedy</td>\n",
       "      <td>1329962476</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>Rome</td>\n",
       "      <td>1329962490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>18</td>\n",
       "      <td>34</td>\n",
       "      <td>royalty</td>\n",
       "      <td>1329962474</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   userId  movieId              tag  timestamp_y\n",
       "0      18       34     Gregory Peck   1329962459\n",
       "1      18       34      need to own   1329962471\n",
       "2      18       34  romantic comedy   1329962476\n",
       "3      18       34             Rome   1329962490\n",
       "4      18       34          royalty   1329962474"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movies_tags.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bdba35d",
   "metadata": {},
   "source": [
    "### Divisão da base em treino e teste"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ca4e983f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train, test = train_test_split(df, test_size=.2, random_state=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0903b1d1",
   "metadata": {},
   "source": [
    "***Exercício 01:*** Aplique a filtragem baseada em conteúdo (ItemAttributeKNN do CaseRecommender) com as tags associadas aos filmes da base. Utilize Jaccard como métrica de similaridade e k=5 vizinhos para predição.\n",
    "\n",
    "Documentação do ItemAttributeKNN: https://github.com/caserec/CaseRecommender/blob/master/caserec/recommenders/rating_prediction/item_attribute_knn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "286944ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case Recommender: Rating Prediction > Item Attribute KNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 405 items (152496 interactions) | sparsity:: 96.60%\n",
      "test data:: 10571 users and 331 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 6.902027 sec\n",
      ">> metadata:: 231 items and 1979 metadata (6274 interactions) | sparsity:: 98.63%\n",
      "prediction_time:: 1.037632 sec\n",
      "Eval:: MAE: 0.736001 RMSE: 0.971392 \n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "\n",
    "from caserec.recommenders.rating_prediction.item_attribute_knn import ItemAttributeKNN\n",
    "\n",
    "# Save the train, test and movies_tags dfs to files as csv\n",
    "train.to_csv('train.dat', index=False, header=False, sep='\\t')\n",
    "test.to_csv('test.dat', index=False, header=False, sep='\\t')\n",
    "movies_tags[['movieId', 'tag']].to_csv('items_tags.dat', index=False, sep='\\t', header=False)\n",
    "\n",
    "# Run the model\n",
    "ItemAttributeKNN('train.dat', 'test.dat', metadata_file='items_tags.dat', output_file='output1.dat', k_neighbors=5, similarity_metric='jaccard', as_similar_first=True).compute()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1d92b0c5-4b50-4acb-b16b-d0e4a6712e94",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>predRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36744</th>\n",
       "      <td>10697</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>I, Robot (2004)</td>\n",
       "      <td>3.189875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6430</th>\n",
       "      <td>1869</td>\n",
       "      <td>8</td>\n",
       "      <td>2.5</td>\n",
       "      <td>Karate Kid, The (1984)</td>\n",
       "      <td>3.128377</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24019</th>\n",
       "      <td>7007</td>\n",
       "      <td>18</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Life Is Beautiful (La Vita è bella) (1997)</td>\n",
       "      <td>4.099691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28034</th>\n",
       "      <td>8169</td>\n",
       "      <td>84</td>\n",
       "      <td>3.5</td>\n",
       "      <td>National Treasure: Book of Secrets (2007)</td>\n",
       "      <td>3.423931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22015</th>\n",
       "      <td>6399</td>\n",
       "      <td>27</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Zero Effect (1998)</td>\n",
       "      <td>3.274535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating                                       title  \\\n",
       "36744   10697        5     3.0                             I, Robot (2004)   \n",
       "6430     1869        8     2.5                      Karate Kid, The (1984)   \n",
       "24019    7007       18     5.0  Life Is Beautiful (La Vita è bella) (1997)   \n",
       "28034    8169       84     3.5   National Treasure: Book of Secrets (2007)   \n",
       "22015    6399       27     3.0                          Zero Effect (1998)   \n",
       "\n",
       "       predRating  \n",
       "36744    3.189875  \n",
       "6430     3.128377  \n",
       "24019    4.099691  \n",
       "28034    3.423931  \n",
       "22015    3.274535  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predictions result output file\n",
    "predictions = pd.read_csv('output1.dat', sep='\\t', header=None, names=['userId', 'movieId', 'predRating'])\n",
    "\n",
    "# Merge the original df and predictions on userId and movieId to compare\n",
    "merged_df = pd.merge(df, predictions, on=['userId', 'movieId'], how='inner')\n",
    "\n",
    "# Print a sample from the merged dataframe\n",
    "merged_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "29a59065",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "### Preparação para o exercício 2 - Download e extração de metadados multimídia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c053c9d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Saved under ml-20m-features.tar (12).gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "x features/\n",
      "x features/._m4infus_max_histogram_300_sn.arq\n",
      "x features/m4infus_max_histogram_300_sn.arq\n",
      "x features/._mm_avg_histogram_100_sn.arq\n",
      "x features/mm_avg_histogram_100_sn.arq\n",
      "x features/._visual_histogram_100_sn.arq\n",
      "x features/visual_histogram_100_sn.arq\n",
      "x features/._visual_histogram_50_sn.arq\n",
      "x features/visual_histogram_50_sn.arq\n",
      "x features/._aural_histogram_50.arq\n",
      "x features/aural_histogram_50.arq\n",
      "x features/._mm_max_histogram_300.arq\n",
      "x features/mm_max_histogram_300.arq\n",
      "x features/._m4infus_max_histogram_50.arq\n",
      "x features/m4infus_max_histogram_50.arq\n",
      "x features/._mm_max_histogram_100.arq\n",
      "x features/mm_max_histogram_100.arq\n",
      "x features/._mm_max_histogram_50_sn.arq\n",
      "x features/mm_max_histogram_50_sn.arq\n",
      "x features/._visual_histogram_100.arq\n",
      "x features/visual_histogram_100.arq\n",
      "x features/._visual_histogram_300.arq\n",
      "x features/visual_histogram_300.arq\n",
      "x features/._aural_histogram_100_sn.arq\n",
      "x features/aural_histogram_100_sn.arq\n",
      "x features/._mm_avg_histogram_100.arq\n",
      "x features/mm_avg_histogram_100.arq\n",
      "x features/._mm_max_histogram_100_sn.arq\n",
      "x features/mm_max_histogram_100_sn.arq\n",
      "x features/._mm_sum_histogram_100_sn.arq\n",
      "x features/mm_sum_histogram_100_sn.arq\n",
      "x features/._mm_avg_histogram_300.arq\n",
      "x features/mm_avg_histogram_300.arq\n",
      "x features/._visual_histogram_300_sn.arq\n",
      "x features/visual_histogram_300_sn.arq\n",
      "x features/._mm_avg_histogram_300_sn.arq\n",
      "x features/mm_avg_histogram_300_sn.arq\n",
      "x features/._m4infus_max_histogram_100.arq\n",
      "x features/m4infus_max_histogram_100.arq\n",
      "x features/._m4infus_max_histogram_100_sn.arq\n",
      "x features/m4infus_max_histogram_100_sn.arq\n",
      "x features/._mm_sum_histogram_50_sn.arq\n",
      "x features/mm_sum_histogram_50_sn.arq\n",
      "x features/._m4infus_max_histogram_300.arq\n",
      "x features/m4infus_max_histogram_300.arq\n",
      "x features/._mm_avg_histogram_50_sn.arq\n",
      "x features/mm_avg_histogram_50_sn.arq\n",
      "x features/._mm_sum_histogram_50.arq\n",
      "x features/mm_sum_histogram_50.arq\n",
      "x features/._visual_histogram_50.arq\n",
      "x features/visual_histogram_50.arq\n",
      "x features/._aural_histogram_50_sn.arq\n",
      "x features/aural_histogram_50_sn.arq\n",
      "x features/._mm_sum_histogram_300.arq\n",
      "x features/mm_sum_histogram_300.arq\n",
      "x features/._m4infus_max_histogram_50_sn.arq\n",
      "x features/m4infus_max_histogram_50_sn.arq\n",
      "x features/._mm_max_histogram_50.arq\n",
      "x features/mm_max_histogram_50.arq\n",
      "x features/._mm_avg_histogram_50.arq\n",
      "x features/mm_avg_histogram_50.arq\n",
      "x features/._mm_max_histogram_300_sn.arq\n",
      "x features/mm_max_histogram_300_sn.arq\n",
      "x features/._mm_sum_histogram_300_sn.arq\n",
      "x features/mm_sum_histogram_300_sn.arq\n",
      "x features/._mm_sum_histogram_100.arq\n",
      "x features/mm_sum_histogram_100.arq\n",
      "x features/._aural_histogram_300.arq\n",
      "x features/aural_histogram_300.arq\n",
      "x features/._aural_histogram_300_sn.arq\n",
      "x features/aural_histogram_300_sn.arq\n",
      "x features/._aural_histogram_100.arq\n",
      "x features/aural_histogram_100.arq\n"
     ]
    }
   ],
   "source": [
    "!python -m wget https://github.com/mmanzato/MBABigData/raw/master/ml-20m-features.tar.gz\n",
    "! tar -xvzf ml-20m-features.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f84ec88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No. movies: 433\n",
      "Size of each word: 50\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('./features/visual_histogram_50.arq', 'rb') as arq_visualHistograms:\n",
    "    visualHistograms = pickle.load(arq_visualHistograms)\n",
    "print('No. movies: ' + str(len(visualHistograms)))\n",
    "print('Size of each word: ' + str(len(visualHistograms[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b5eea7d0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00948992, 0.00237248, 0.00355872, 0.01304864, 0.05338078,\n",
       "       0.00711744, 0.05456702, 0.00355872, 0.0059312 , 0.00355872,\n",
       "       0.0059312 , 0.00474496, 0.00711744, 0.04507711, 0.07591934,\n",
       "       0.00355872, 0.1316726 , 0.05338078, 0.00830368, 0.        ,\n",
       "       0.01304864, 0.00474496, 0.02253855, 0.00355872, 0.02728351,\n",
       "       0.00237248, 0.02016607, 0.00830368, 0.0059312 , 0.00237248,\n",
       "       0.00355872, 0.04033215, 0.01067616, 0.00237248, 0.00830368,\n",
       "       0.05931198, 0.0059312 , 0.01067616, 0.02965599, 0.01423488,\n",
       "       0.00711744, 0.02609727, 0.        , 0.00237248, 0.01423488,\n",
       "       0.03084223, 0.02016607, 0.00118624, 0.08778173, 0.02253855])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "visualHistograms[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "576dc392",
   "metadata": {},
   "source": [
    "***Exercício 02:*** Como visto, o algoritmo ItemAttributeKNN pode ser usado com diferentes tipos de metadados, como gêneros, tags e palavras no geral. Mais do que isso, podemos adaptá-lo também para que a similaridade entre itens seja feita com base em informações multimídia, como imagens, áudio, etc. \n",
    "\n",
    "A base de dados utilizada até o momento, ml-20m-compact.tar.gz possui, além das interações de usuários com filmes, uma série de arquivos que contém informações multimídia que foram extraídas dos trailers de cada filme. Esses arquivos estão condensados no zip ml-20m-features.tar.gz, o qual foi feito o download e extraído acima. \n",
    "\n",
    "Considere por exemplo o arquivo visual_histogram_50.arq. Ele possui 433 vetores (no. de filmes) de tamanho 50. Podemos pensar que cada vetor desse representa informações visuais (cor, brilho, imagem, etc.) que foram extraídas dos trailers de cada filme. \n",
    "\n",
    "Sua tarefa é usar esses vetores de características visuais no cálculo de similaridade entre os filmes, e em seguida, aplicar essas similaridades no algoritmo ItemAttributeKNN para gerar recomendações. \n",
    "\n",
    "Dica 1: para calcular a similaridade entre dois vetores pode-se usar o ângulo de cosseno (vide https://en.wikipedia.org/wiki/Cosine_similarity). \n",
    "\n",
    "Dica 2: é possível passar para o algoritmo ItemAttributeKNN a matriz de similaridade entre itens, por meio do parâmetro similarity_file=arquivo. Veja em: https://github.com/caserec/CaseRecommender/blob/master/caserec/recommenders/rating_prediction/item_attribute_knn.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "fb885853",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Case Recommender: Rating Prediction > Item Attribute KNN Algorithm]\n",
      "\n",
      "train data:: 11090 users and 405 items (152496 interactions) | sparsity:: 96.60%\n",
      "test data:: 10571 users and 331 items (38125 interactions) | sparsity:: 98.91%\n",
      "\n",
      "training_time:: 6.408458 sec\n",
      ">> metadata:: 231 items and 1979 metadata (6274 interactions) | sparsity:: 98.63%\n",
      "prediction_time:: 0.552928 sec\n",
      "Eval:: MAE: 0.729791 RMSE: 0.959396 \n"
     ]
    }
   ],
   "source": [
    "# TODO\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "# Calculate the similarity using the cosine_similarit from sklearn\n",
    "similarity_matrix = cosine_similarity(visualHistograms)\n",
    "\n",
    "# Save the similarity_matrix as a file \n",
    "np.savetxt('similarity_matrix.arq', similarity_matrix)\n",
    "\n",
    "# Run the model using the similarity_matrix\n",
    "ItemAttributeKNN('train.dat', 'test.dat', metadata_file='items_tags.dat', output_file='output2.dat', k_neighbors=5, similarity_file='similarity_matrix.arq', as_similar_first=True).compute()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b91c2350-11fa-4fd6-b485-e81a5d41b35c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>userId</th>\n",
       "      <th>movieId</th>\n",
       "      <th>rating</th>\n",
       "      <th>title</th>\n",
       "      <th>predRating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7556</th>\n",
       "      <td>2191</td>\n",
       "      <td>19</td>\n",
       "      <td>3.5</td>\n",
       "      <td>Reservoir Dogs (1992)</td>\n",
       "      <td>4.001801</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36760</th>\n",
       "      <td>10702</td>\n",
       "      <td>14</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Go (1999)</td>\n",
       "      <td>3.647070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>819</th>\n",
       "      <td>246</td>\n",
       "      <td>103</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Red (2010)</td>\n",
       "      <td>2.956513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20877</th>\n",
       "      <td>6056</td>\n",
       "      <td>22</td>\n",
       "      <td>5.0</td>\n",
       "      <td>Natural Born Killers (1994)</td>\n",
       "      <td>4.203375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11092</th>\n",
       "      <td>3248</td>\n",
       "      <td>129</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Interstellar (2014)</td>\n",
       "      <td>3.613136</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       userId  movieId  rating                        title  predRating\n",
       "7556     2191       19     3.5        Reservoir Dogs (1992)    4.001801\n",
       "36760   10702       14     5.0                    Go (1999)    3.647070\n",
       "819       246      103     3.0                   Red (2010)    2.956513\n",
       "20877    6056       22     5.0  Natural Born Killers (1994)    4.203375\n",
       "11092    3248      129     4.0          Interstellar (2014)    3.613136"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the predictions result output file\n",
    "predictions = pd.read_csv('output2.dat', sep='\\t', header=None, names=['userId', 'movieId', 'predRating'])\n",
    "\n",
    "# Merge the original df and predictions on userId and movieId to compare\n",
    "merged_df = pd.merge(df, predictions, on=['userId', 'movieId'], how='inner')\n",
    "\n",
    "# Print the first 5 rows from the merged dataframe\n",
    "merged_df.sample(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1eff8e",
   "metadata": {},
   "source": [
    "***Exercício 03:*** Implementar uma função que retorna a probabilidade de um item ser relevante para um usuário, considerando os gêneros dos filmes. Utilize métodos probabilísticos. \n",
    "- A partir do conjunto de treinamento, obter todas as interações do usuário u.\n",
    "- Rotular as notas desse usuário como: item relevante se nota >=3 e não relevante se nota < 3. \n",
    "- Dado um item do conjunto de teste, aplicar o Teorema de Bayes com suavização de Laplace. Utilizar os gêneros associados. \n",
    "- Retornar se o item é ou não relevante, e em seguida, comparar o resultado com a nota real que esse usuário deu para o item (disponível no conjunto de teste)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "64d5a0d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "O filme Reservoir Dogs (1992) é classificado como relevante para o usuário 1464.\n",
      "A nota real dada pelo usuário foi: 4.5\n",
      "O filme She's the Man (2006) é classificado como relevante para o usuário 1836.\n",
      "A nota real dada pelo usuário foi: 2.5\n",
      "O filme Deep End of the Ocean, The (1999) é classificado como relevante para o usuário 7518.\n",
      "A nota real dada pelo usuário foi: 3.0\n",
      "O filme Alphaville (Alphaville, une étrange aventure de Lemmy Caution) (1965) é classificado como não relevante para o usuário 6472.\n",
      "A nota real dada pelo usuário foi: 1.5\n",
      "O filme American Psycho (2000) é classificado como não relevante para o usuário 1165.\n",
      "A nota real dada pelo usuário foi: 2.0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Create a new df so each movie has each genre in separated rows\n",
    "movies_genres = movies.drop('genres', axis=1).join(movies.genres.str.split('|', expand=True)\n",
    "             .stack().reset_index(drop=True, level=1).rename('genre'))\n",
    "\n",
    "# Merge the train df and the movies_genres df to add the genre of the movies\n",
    "df_merged = pd.merge(train, movies_genres, on=['title'])\n",
    "\n",
    "# Add a column that is 1 if rating >= 3 or 0 if not\n",
    "df_merged['relevant'] = (df_merged['rating'] >= 3).astype(int)\n",
    "\n",
    "# Function that calculates if a movie is relevant or not to a specific user, if\n",
    "# the probability is larger than 0.5, then its relevant\n",
    "def calculate_relevance_probability(user_id, movie_id, df_merged, test_df):\n",
    "    # Get the interactions of the specific user \n",
    "    user_interactions = df_merged[df_merged['userId'] == user_id]\n",
    "    \n",
    "    # Get the genres of the specific movie\n",
    "    movie_genres = df_merged[df_merged['movieId_x'] == movie_id]['genre'].unique().tolist()\n",
    "   \n",
    "    total_relevant = 0\n",
    "    total_not_relevant = 0\n",
    "    genre_count_relevant = defaultdict(int)\n",
    "    genre_count_not_relevant = defaultdict(int)\n",
    "    \n",
    "    # Label movies as relevant (rating >= 3) or not relevant (rating < 3)\n",
    "    for _, row in user_interactions.iterrows():\n",
    "        genres = row['genre']\n",
    "        relevant = row['relevant']\n",
    "        \n",
    "        if relevant:\n",
    "            total_relevant += 1\n",
    "            for genre in genres:\n",
    "                genre_count_relevant[genre] += 1\n",
    "        else:\n",
    "            total_not_relevant += 1\n",
    "            for genre in genres:\n",
    "                genre_count_not_relevant[genre] += 1\n",
    "    \n",
    "    # Total number of unique genres\n",
    "    unique_genres = set(genre_count_relevant.keys()).union(set(genre_count_not_relevant.keys()))\n",
    "    total_unique_genres = len(unique_genres)\n",
    "    \n",
    "    # Calculate probabilities using Laplace smoothing\n",
    "    prob_relevant = total_relevant / (total_relevant + total_not_relevant)\n",
    "    prob_not_relevant = total_not_relevant / (total_relevant + total_not_relevant)\n",
    "    \n",
    "    prob_genre_given_relevant = 1\n",
    "    prob_genre_given_not_relevant = 1\n",
    "    \n",
    "    for genre in movie_genres:\n",
    "        # Probability of seeing the genre given the movie is relevant or not, with Laplace smoothing\n",
    "        prob_genre_given_relevant *= (genre_count_relevant[genre] + 1) / (total_relevant + total_unique_genres)\n",
    "        prob_genre_given_not_relevant *= (genre_count_not_relevant[genre] + 1) / (total_not_relevant + total_unique_genres)\n",
    "    \n",
    "    # Calculate the final probability using Bayes' Theorem\n",
    "    final_prob_relevant = prob_genre_given_relevant * prob_relevant\n",
    "    final_prob_not_relevant = prob_genre_given_not_relevant * prob_not_relevant\n",
    "    \n",
    "    # Normalize to get the probability\n",
    "    total_prob = final_prob_relevant + final_prob_not_relevant\n",
    "    if total_prob == 0:\n",
    "        return 0  # To handle division by zero if both probabilities are zero\n",
    "    final_prob = final_prob_relevant / total_prob\n",
    "    \n",
    "    # Determine if the movie is relevant\n",
    "    is_relevant = final_prob >= 0.5\n",
    "    \n",
    "    # Get the actual rating for comparison from the test df\n",
    "    actual_rating = test_df[(test_df['userId'] == user_id) & (test_df['movieId'] == movie_id)]['rating']\n",
    "    actual_rating = actual_rating.values[0] if not actual_rating.empty else None\n",
    "\n",
    "    print(f\"O filme {merged_df[merged_df['movieId'] == movie_id]['title'].values[0]} é classificado como {'relevante' if is_relevant else 'não relevante'} para o usuário {user_id}.\")\n",
    "    if actual_rating is not None:\n",
    "        print(f\"A nota real dada pelo usuário foi: {actual_rating}\")\n",
    "    else:\n",
    "        print(\"Nota real não disponível.\")\n",
    "            \n",
    "\n",
    "calculate_relevance_probability(1464, 19, df_merged, test)\n",
    "calculate_relevance_probability(1836, 60, df_merged, test)\n",
    "calculate_relevance_probability(7518, 24, df_merged, test)\n",
    "calculate_relevance_probability(6472, 112, df_merged, test)\n",
    "calculate_relevance_probability(1165, 3, df_merged, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524fa3c1",
   "metadata": {},
   "source": [
    "***Exercício 04:*** No notebook de exemplos, existe uma implementação de Filtragem Baseada em Conteúdo usando Multi-Layer Perceptron como um regressor (MLPRegressor) que prevê a nota de cada usuário para filmes ainda não vistos. O algoritmo retorna uma lista de top K filmes com maiores notas. O treinamento é realizado utilizando as notas que o usuário deu para os filmes e seus respectivos gêneros.\n",
    "- Usando a classe MLPClassifier (https://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPClassifier.html), implemente uma versão que classifica os filmes não vistos como relevante ou não-relevante.\n",
    "- No conjunto de dados, realize a binarização das notas, de modo que notas acima de 3 são relevantes e notas abaixo de 3 são não-relevantes.\n",
    "- Retorne os top k filmes mais relevantes.\n",
    "- Para um usuário qualquer da base (ou algum outro usuário fictício), analise subjetivamente a qualidade das recomendações, comparando os modelos MLPRegressor e MLPClassifier. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "02cf6df5-c2e1-4a0a-90fe-1d3c18d8535b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "genres_unique = pd.DataFrame(movies.genres.str.split('|').tolist()).stack().unique()\n",
    "genres_unique = pd.DataFrame(genres_unique, columns=['genre'])\n",
    "movies_exp = movies.join(movies.genres.str.get_dummies().astype(bool))\n",
    "movies_exp.drop('genres', inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4d83709b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 10 filmes recomendados:\n",
      "                                                 title  predicted_relevance\n",
      "12   Alphaville (Alphaville, une étrange aventure d...             1.000000\n",
      "240                                     Balance (1989)             1.000000\n",
      "194                                  Quiet, The (2005)             0.999999\n",
      "136                                       Frogs (1972)             0.999999\n",
      "162                                   Boogeyman (2005)             0.999999\n",
      "216                              Happening, The (2008)             0.999998\n",
      "229                             Hangover Square (1945)             0.999998\n",
      "190                         Seventh Victim, The (1943)             0.999997\n",
      "31                            Conspiracy Theory (1997)             0.999996\n",
      "100           Horror Planet (a.k.a. Inseminoid) (1981)             0.999996\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "\n",
    "# Initialize objects to store the models\n",
    "user_models_mlp_class = {}\n",
    "\n",
    "# For each user, train a model\n",
    "for user_id in train['userId'].unique():\n",
    "    # Get the movies rated by the user\n",
    "    user_ratings = train[(train['userId'] == user_id)]\n",
    "\n",
    "    # Get the movies rated by the user with the genres\n",
    "    user_movies = pd.merge(user_ratings, movies_exp, on='title')\n",
    "\n",
    "    if len(user_movies) > 1:\n",
    "        # Prepare data for MLP training\n",
    "        X = user_movies.drop(['userId', 'movieId_x', 'movieId_y', 'rating', 'title'], axis=1)\n",
    "        \n",
    "        # Binzarize the ratings (relevant (1) if rating >= 3, not-relevant (0) if rating < 3)\n",
    "        y = (user_movies['rating'] >= 3).astype(int)\n",
    "\n",
    "        # Train MLPClassifier\n",
    "        mlp_class = MLPClassifier(hidden_layer_sizes=(50, 30), activation='relu', max_iter=1000, random_state=42)\n",
    "        mlp_class.fit(X, y)\n",
    "\n",
    "        # Save the model for each user\n",
    "        user_models_mlp_class[user_id] = mlp_class\n",
    "\n",
    "\n",
    "def recommend_movies(user_id, k=10):\n",
    "    if user_id in user_models_mlp_class:\n",
    "        # Get the user model\n",
    "        mlp_class = user_models_mlp_class[user_id]\n",
    "        \n",
    "        # Predict the relevance for all movies\n",
    "        all_movies = movies_exp.drop(['movieId', 'title'], axis=1)\n",
    "        predicted_probabilities = mlp_class.predict_proba(all_movies)[:, 1]  # Probabilidade de ser relevante (classe 1)\n",
    "\n",
    "        # Add the predictions to the original df\n",
    "        movies_exp['predicted_relevance'] = predicted_probabilities\n",
    "\n",
    "        # Remove the movies that the user already rated\n",
    "        user_rated_movies = train[train['userId'] == user_id]['movieId']\n",
    "        recommended_movies = movies_exp[~movies_exp['movieId'].isin(user_rated_movies)]\n",
    "\n",
    "        # Order the movies by predict relevance and show the top k\n",
    "        recommended_movies = recommended_movies.sort_values(by='predicted_relevance', ascending=False)\n",
    "\n",
    "        return recommended_movies[['title', 'predicted_relevance']].head(k)\n",
    "    else:\n",
    "        return f\"User {user_id} does not have enough data to train a model.\"\n",
    "\n",
    "# Test for user 20\n",
    "top_movies = recommend_movies(20, k=10)\n",
    "print(\"Top 10 filmes recomendados:\")\n",
    "print(top_movies)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53e906d3-d23d-4783-97d7-0616425c6c87",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
